{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Predicting Boston Housing Prices\n",
    "## Nanodegree Machine Learning Engineer\n",
    "The goal of this project is to develop a machine learning model to predict boston housing pricing based of infomation such as (number of room, neighborhood poverty, and student-teacher ratio). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data \n",
    "Before develop and train the model, data must be import to the program. As included with the program, the file 'housing.csv' contain the data that is collected in the boston area for housing's price. The block of code bellow is used to import data into the program ready for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset has 489 data points with 4 variables each.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "    \n",
    "# Success\n",
    "print \"Boston housing dataset has {} data points with {} variables each.\".format(*data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "To provide a general idea of what the data is like, the following statistical infomation of the data will be calcuated:\n",
    " * Minimum price of the house\n",
    " * Maximum price of the house\n",
    " * Mean price of the house\n",
    " * Medium price of the house\n",
    " * Standard deviation of the prices of the house\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Boston housing dataset:\n",
      "\n",
      "Minimum price: $105,000.00\n",
      "Maximum price: $1,024,800.00\n",
      "Mean price: $454,342.94\n",
      "Median price $438,900.00\n",
      "Standard deviation of prices: $165,171.13\n"
     ]
    }
   ],
   "source": [
    "# Calculate minimum price of the data\n",
    "minimum_price = min(prices)\n",
    "\n",
    "# Calculate maximum price of the data\n",
    "maximum_price = max(prices)\n",
    "\n",
    "# TCalculate mean price of the data\n",
    "mean_price = np.mean(prices)\n",
    "\n",
    "# TCalculate median price of the data\n",
    "median_price = np.median(prices)\n",
    "\n",
    "# Calculate standard deviation of prices of the data\n",
    "std_price = np.std(prices)\n",
    "\n",
    "# Show the calculated statistics\n",
    "print \"Statistics for Boston housing dataset:\\n\"\n",
    "print \"Minimum price: ${:,.2f}\".format(minimum_price)\n",
    "print \"Maximum price: ${:,.2f}\".format(maximum_price)\n",
    "print \"Mean price: ${:,.2f}\".format(mean_price)\n",
    "print \"Median price ${:,.2f}\".format(median_price)\n",
    "print \"Standard deviation of prices: ${:,.2f}\".format(std_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Developing a Model\n",
    "In this section of the project, a model will be develop to make prediction on the price of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r2_score\n",
    "The r2 score is the coefficient of determination. The r2 score determines goodness of the fit of the model to the data point. The maximum score is 1. \n",
    "* 0% indicates that the model explains none of the variability of the response data around its mean.\n",
    "* 100% indicates that the model explains all of the variability of the response data around its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import 'r2_score'\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test for the performance_metric function\n",
    "Assume that a dataset contains five data points and a model made the following predictions for the target variable:\n",
    "\n",
    "| True Value | Prediction |\n",
    "| :-------------: | :--------: |\n",
    "| 3.0 | 2.5 |\n",
    "| -0.5 | 0.0 |\n",
    "| 2.0 | 2.1 |\n",
    "| 7.0 | 7.8 |\n",
    "| 4.2 | 5.3 |\n",
    "\n",
    "The code cell below use the `performance_metric` function and calculate this model's coefficient of determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has a coefficient of determination, R^2, of 0.923.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the performance of this model\n",
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print \"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result turns out to be 92.3%; this is not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Shuffle and Split Data\n",
    "* Data must be split into two sets (training and testing) to train and validate the model. If most of the data are being used to train, a limited amount of data to test for model validation. If the test data is too big, then there is enough data to train the model. Thus, find the optimal ratio between train and test data is crucial to train and validate the model.\n",
    "* For this data, 30% of the data will be used for model validation, and the rest will be used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "# Import 'train_test_split'\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, test_size=0.3, random_state=42)\n",
    "\n",
    "# Success\n",
    "print \"Training and testing split was successful.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Evaluating Model Performance\n",
    "In this final section of the project, a model will be constructed and make a prediction on the client's feature set using an optimized model from `fit_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Fitting a Model\n",
    "* In this project **decision tree algorithm** will be used to develop a model to predict the housing price. \n",
    "* ShuffleSplit will be used to split the data into training and test sets. \n",
    "* Decision Tree Regressor will be used to develop the machine learning algorithm. \n",
    "* To produce an accurate and robust machine learning model to predict the optimal result, the machine learning parameter must be tuned to the optimal. For un-seem data set like this, GridSearchCV will be used to test a varieties parameters for the model to optimize it.\n",
    "\n",
    "* In this case, the fit_model function will help to determine the best max_depth for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    # sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n",
    "    # sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth': [1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "    # TTransform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    # Make sure to include the right parameters in the object:\n",
    "    # (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "    grid = GridSearchCV(regressor, params)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal max_depth\n",
    "The code bellow the use the fit_model function test produce the optimal valve for max_depth of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 4 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "# Fit the training data to the model using grid search\n",
    "reg = fit_model(features, prices)\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print \"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Selling Prices\n",
    "The table bellow is the data to predict the price using the machine learning model that is aready trained. Run the code section bellow to see the result\n",
    "\n",
    "| Feature | Client 1 | Client 2 | Client 3 |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| Total number of rooms in home | 5 rooms | 4 rooms | 8 rooms |\n",
    "| Neighborhood poverty level (as %) | 17% | 32% | 3% |\n",
    "| Student-teacher ratio of nearby schools | 15-to-1 | 22-to-1 | 12-to-1 |\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted selling price for Client 1's home: $408,800.00\n",
      "Predicted selling price for Client 2's home: $231,253.45\n",
      "Predicted selling price for Client 3's home: $938,053.85\n"
     ]
    }
   ],
   "source": [
    "# Produce a matrix for client data\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(reg.predict(client_data)):\n",
    "    print \"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
